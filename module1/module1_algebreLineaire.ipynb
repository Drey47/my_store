{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9007fc15-f4e8-475c-bed8-ef4c87274d28",
   "metadata": {},
   "source": [
    "# **Mathématiques pour l'Intelligence Artificielle**  \n",
    "### International Olympiad in Artificial Intelligence (IOAI) 2025\n",
    "### Trainer : Audrey FANGNON  \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254578df-c013-441c-b183-2998447b9bd6",
   "metadata": {},
   "source": [
    "## **Chapitre 1 : Algèbre Linéaire**  \n",
    "##### C'est quoi ? L’algèbre linéaire est la branche des mathématiques qui s'intéresse aux espaces vectoriels et aux transformations linéaires.\n",
    "##### Role: Il fournit les outils mathématiques pour représenter, manipuler et optimiser les données et les modèles en intelligence artificielle.\n",
    "##### Vocabulaire: \n",
    "- **Espace vectoriel** : Un ensemble de vecteurs fermé sous addition et multiplication par un scalaire (ex: $(ℝ^n, +, \\times)$).  \n",
    "- **Base** : Un ensemble de vecteurs linéairement indépendants qui engendrent l'espace (ex: $((1,0),(0,1))$ est une base de $ℝ^2$) \n",
    "- **Dimension** : Nombre de vecteurs dans une base (ex: dim$(\\mathbb{R}^3) = 3$))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d115de8-729e-4cb8-b030-2611113957ba",
   "metadata": {},
   "source": [
    "### **1.1. Vecteurs** \n",
    "\n",
    "----\n",
    "\n",
    "### **1.1.1. Notion de base sur les vecteurs**  \n",
    "\n",
    "----\n",
    "  \n",
    "### **A. Définition et représentation**  \n",
    "Un **vecteur** est un objet mathématique caractérisé par :  \n",
    "  - **Une direction**: celle du support du vecteur.\n",
    "  - **Un sens**: le sens de parcours du vecteur.\n",
    "  - **Une norme**: la longueur du vecteur.  \n",
    "  \n",
    "**Exemple :** Si A et B sont deux points distincts, quelles sont les caractéristiques de $\\overrightarrow{AB}$ ?\n",
    "  - **Direction:**  ---\n",
    "  - **Sens:**  --\n",
    "  - **Norme:** --\n",
    "\n",
    "\n",
    "### **B. Opérations de base**  \n",
    "Considerons deux vecteurs $ \\vec{u}(u_1, u_2, ..., u_n)$ et $\\vec{v}(v_1, v_2, ..., v_n)$ de $\\mathbb{R}^n$\n",
    "- **Addition** : $  \\vec{u} + \\vec{v} = \\begin{pmatrix} u_1 + v_1 \\\\ u_2 + v_2 \\\\ . \\\\ . \\\\ . \\\\ u_n + v_n \\end{pmatrix}  $\n",
    "- **Multiplication par un scalaire** : $  \\lambda \\vec{v} = \\begin{pmatrix} \\lambda v_1 \\\\ \\lambda v_2 \\\\ . \\\\ . \\\\ . \\\\ \\lambda v_n \\end{pmatrix} $ où $\\lambda$ est un scalaire (élément de $\\mathbb{R}$ ou de $\\mathbb{C}$)\n",
    "\n",
    "### **C. Vecteurs en IA**  \n",
    "En machine learning, un vecteur peut représenter :  \n",
    "- Un point dans un espace de caractéristiques (*features*).\n",
    "- Des mots et phrases (word embeddings en NLP) \n",
    "- Les poids dans un réseau de neurones.\n",
    "\n",
    "### **Exercices d'application (1.1.1)**  \n",
    "1. Soient $ \\vec{u} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} $ et $ \\vec{v} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} $.\n",
    "Calculez $  \\vec{u} + \\vec{v}  $ et  $  2\\vec{v} - \\vec{u}. $\n",
    "2. Représentez graphiquement $ \\vec{w} = \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} $ dans le plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ceb208-e5b7-43d1-aac2-e0c4715e09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "u = np.array([2, 1]) ; v = np.array([2, 0])\n",
    "print(f\" u + v : {u + v} \\n 2v - u : {2*v-u}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123dd07-ffaa-40ea-b049-d923baa9c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Définition des points A, B et C puis Calcul des vecteurs\n",
    "A = np.array([0, 0]); B = np.array([2, 1]) ; C = np.array([4, 1])\n",
    "AB = B - A; BC = C - B; AC = C - A\n",
    "# Création de la figure\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "ax.quiver(*A, *AB, angles='xy', scale_units='xy', scale=1, color='blue')\n",
    "ax.quiver(*B, *BC, angles='xy', scale_units='xy', scale=1, color='green')\n",
    "ax.quiver(*A, *AC, angles='xy', scale_units='xy', scale=1, color='red')\n",
    "# Ajout des points\n",
    "for point, name in zip([A, B, C], ['A', 'B', 'C']):\n",
    "    ax.plot(*point, 'ko')\n",
    "    ax.text(point[0] + 0.1, point[1] + 0.1, name, fontsize=12)\n",
    "# Configuration de l'axe\n",
    "plt.grid(True)\n",
    "plt.title(f\"Titre : Relation de Chasles {'  '*20}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338536a2-248f-43f3-94f8-779f4b2408fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c75a0f5-865c-4c8f-99b7-6072753991c4",
   "metadata": {},
   "source": [
    "----\n",
    "### **1.1.2. Produit scalaire et applications**  \n",
    "----\n",
    "\n",
    "#### **A. Définition**  \n",
    "\n",
    "##### Définition 1: (Projective)\n",
    "Le produit scalaire de deux vecteurs $\\vec{u}$ et $\\vec{v}$ est défini par: \n",
    "$$ \\vec{u} \\cdot \\vec{v} = \\|\\vec{u}\\| \\times \\|\\vec{v}\\| \\times cos(\\vec{u}, \\vec{v}) $$\n",
    "\n",
    "\n",
    "##### Définition 2: (Dans $\\mathbb{R}^n$)\n",
    "Le produit scalaire de deux vecteurs $ \\vec{u}(u_1, u_2, ..., u_n)$ et $\\vec{v}(v_1, v_2, ..., v_n)$ de $\\mathbb{R}^n$ est :  \n",
    "$$ \\vec{u} \\cdot \\vec{v} = \\sum_{i = 1}^{n} {u_i \\times v_i} = u_1 v_1 + u_2 v_2 + \\dots + u_n v_n $$  \n",
    "\n",
    "#### **B. Propriétés**  \n",
    "- **Symétrie** : $ \\vec{u} \\cdot \\vec{v} = \\vec{v} \\cdot \\vec{u} $  \n",
    "- **Linéarité** : $ \\vec{u} \\cdot (\\vec{v} + \\vec{w}) = \\vec{u} \\cdot \\vec{v} + \\vec{u} \\cdot \\vec{w} $\n",
    "\n",
    "#### **C. Interprétation**\n",
    "![Interpretaion du produit scalaire](produit_scalaire_interpretation.png)\n",
    " - À gauche (produit scalaire positif) : les vecteurs pointes dans des directions presque similaires.\n",
    " - Au milieu (produit scalaire négatif) : les vecteurs pointes dans des directions presque opposées.\n",
    " - À droite (produit scalaire nul): les vecteurs pointes dans des directions différente.\n",
    "\n",
    "#### **D. Applications en IA**  \n",
    "- **Similarité cosinus** : Mesure la similarité entre deux vecteurs.  \n",
    "  $\\cos(\\theta) = \\frac{\\vec{u} \\cdot \\vec{v}}{\\|\\vec{u}\\| \\|\\vec{v}\\|} $  \n",
    "Si le cosinus est proche de 1, les vecteurs pointent dans la même direction (ils sont similaires).\n",
    "\n",
    "- Utilisé en NLP (*Natural Language Processing*) pour comparer des documents, mots, phrases (word embeddings).  \n",
    "  \n",
    "### **Exercices d'application (1.1.2)**\n",
    "On donne les vecteurs : $\\vec{u} = \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix}$, $ \\vec{v} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$, $\\vec{w} = \\begin{pmatrix} 2 \\\\ -7 \\end{pmatrix}$ et $\\vec{\\Omega} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$.\n",
    "1. Calculez $\\vec{\\Omega} \\cdot \\vec{u}$, $\\vec{\\Omega} \\cdot \\vec{v}$ et $\\vec{\\Omega} \\cdot \\vec{w}$.  \n",
    "2. En utilisant la similarité cosinus trouve :  \n",
    "   2.1. le vecteur le plus similaire à $\\vec{\\Omega}$.  \n",
    "   2.2. le vecteur le moins similaire à $\\vec{\\Omega}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154debb-b180-4b0f-8289-8c2370758a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration\n",
    "u = np.array([0, 2]) ; v = np.array([2, 1]) ; w = np.array([3, -2]) ; omega = np.array([1, -2]) ; O = np.array([0, 0]) \n",
    "# Création de la figure\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "ax.quiver(*O, *u, angles='xy', scale_units='xy', scale=1, color='blue')\n",
    "ax.quiver(*O, *v, angles='xy', scale_units='xy', scale=1, color='green')\n",
    "ax.quiver(*O, *w, angles='xy', scale_units='xy', scale=1, color='red')\n",
    "ax.quiver(*O, *omega, angles='xy', scale_units='xy', scale=1, color='yellow')\n",
    "# Ajout des points et calcul de similarité\n",
    "for point, name in zip([u, v, w, omega], ['u', 'v', 'w', 'omega']):\n",
    "    ax.plot(*point)\n",
    "    ax.text(point[0] + 0.1, point[1] + 0.1, name, fontsize=12)\n",
    "# Configuration de l'axe\n",
    "plt.grid(True)\n",
    "plt.title(f\"Graphique: application 1.1.3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50837876-418f-4a91-8813-6e14c617f914",
   "metadata": {},
   "source": [
    "### TP : Utilisation des vecteurs en NLP et Similarité cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a81714-e6da-467e-b33e-dbf513c149a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-genai\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "GEMINI_API_KEY='AIzaSyBPp-b8SicH-_NzQcwtUX36z6G186zFAMA'\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "def vectorize(input, model=\"gemini-embedding-exp-03-07\"):\n",
    "    result = client.models.embed_content(\n",
    "            model=model,\n",
    "            contents=input\n",
    "    )\n",
    "    return np.array(result.embeddings[0].values).reshape(1, -1)\n",
    "print(cosine_similarity(vectorize(\"Il fait beau\"), vectorize(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348562-fdc7-4488-a2bd-aec62f732c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aaa5b30-2f01-470a-88eb-0c9911bdcd2b",
   "metadata": {},
   "source": [
    "----\n",
    "### **1.1.3. Normes (L1, L2)**  \n",
    "----\n",
    "Les normes L1 et L2 donnent des mesures différentes de la \"taille\" d'un vecteur, avec des interprétations géométriques distinctes.  \n",
    "\n",
    "#### **A. Norme L1 (Norme Manhattan)**  \n",
    "La norme L1 d'un vecteur **$v = (v₁, v₂, ..., vₙ)$** de $\\mathbb{R}^n$ est la somme des valeurs absolues de ses composantes :  \n",
    "$ ||v||_1 = |v_1| + |v_2| + \\dots + |v_n| $ \n",
    "\n",
    "##### **Interprétation géométrique**  \n",
    "- **En 2D/3D** : La norme L1 représente la distance parcourue en suivant un chemin en \"escalier\" (comme les déplacements dans une ville quadrillée, d'où le nom *Manhattan*).  \n",
    "- **Exemple** :  \n",
    "  - Pour **v = (3, 4)** (en 2D), la norme L1 est **7**.  \n",
    "\n",
    "##### **Applications pratiques**  \n",
    "- **En IA** :  \n",
    "  - Utilisée en *régularisation Lasso* pour éliminer les variables non pertinentes (certains coefficients deviennent exactement **0**).  \n",
    "  - Moins sensible aux *outliers* que L2 (car elle ne pénalise pas trop les grandes valeurs).  \n",
    "\n",
    "\n",
    "#### **B. Norme L2 (Norme Euclidienne)**   \n",
    "La norme L2 est la racine carrée de la somme des carrés des composantes :  \n",
    "$ ||v||_2 = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2} $\n",
    "\n",
    "##### **Interprétation géométrique**  \n",
    "- **En 2D/3D** : C'est la distance \"à vol d'oiseau\" entre l'origine et le point représenté par le vecteur.  \n",
    "- **Exemple** :  \n",
    "  - Pour **v = (3, 4)**, la norme L2 est **5** (car $ \\sqrt{3^2 + 4^2} = 5 $).  \n",
    "  - C'est la longueur du segment reliant **(0,0)** à **(3,4)**.   \n",
    "\n",
    "##### **Applications pratiques**  \n",
    "- **En IA** :  \n",
    "  - Utilisée en *régularisation Ridge* pour réduire l'amplitude des coefficients sans les annuler.  \n",
    "  - Très courante en *descente de gradient* (car elle est différentiable partout).  \n",
    "  - Sensible aux *outliers* (car les grandes valeurs sont amplifiées par le carré).  \n",
    "\n",
    "\n",
    "### **Exercices d'application (1.1.3)**\n",
    "\n",
    "Soient $ \\vec{a} = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix} $ et $ \\vec{b} = \\begin{pmatrix} 2 \\\\ -1 \\\\ 3 \\end{pmatrix} $.  \n",
    "1. Calculez $ \\vec{a} \\cdot \\vec{a} $, et $ \\vec{b} \\cdot \\vec{b} $  \n",
    "2. Calculer les normes $ \\| . \\|_1 $ et $ \\| . \\|_2 $ de ces vecteurs.\n",
    "3. Quelle relation y a-t-il entre : **le produit scalaire** et  $ \\| . \\|_2 $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f940d-a8f6-4541-ab25-1d9fbc2d84aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ced33ef8-f338-4f2a-bc9c-9facf1c26b69",
   "metadata": {},
   "source": [
    "## **1.2. Matrices et Applications Linéaires**\n",
    "\n",
    "----\n",
    "### **1.2.1. Matrice et Application Linéaire**  \n",
    "----\n",
    "  \n",
    "#### **A. Définition d’une Matrice**  \n",
    "Une **matrice** est un tableau rectangulaire de nombres réels (ou complexes) disposés en lignes et colonnes.  \n",
    "\n",
    "**Exemple :** \n",
    "\n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}\n",
    "$ $\\quad$\n",
    "$\n",
    "B = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "2 & 9 & 6 \\\\\n",
    "\\end{pmatrix}\n",
    "$ $\\quad$\n",
    "$\n",
    "C = \\begin{pmatrix}\n",
    "4 \\\\\n",
    "0 \\\\\n",
    "7 \\\\\n",
    "\\end{pmatrix}\n",
    "$ $\\quad$\n",
    "$\n",
    "D = \\begin{pmatrix}\n",
    "3 & 2 & 3 \\\\\n",
    "\\end{pmatrix}\n",
    "$ et \n",
    "$\n",
    "I_3 = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$\n",
    "- **Format de la matrice A :** $ ( 3 \\times 3 ) $ (3 lignes, 3 colonnes).  \n",
    "- **Format de la matrice B :** $ ( 2 \\times 3 ) $ (2 lignes, 3 colonnes).\n",
    "\n",
    "\n",
    "\n",
    "#### **B. Application Linéaire et Matrice**  \n",
    "Une **application linéaire** $ f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m $ peut être représentée par une matrice.  \n",
    "\n",
    "**Exemple :**  \n",
    "Soit $ f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3 $ définie par :\n",
    "$ f(x, y, z) = (x + 2y + 3z, 4x + 5y + 6z, 7x + 8y + 9z) $  \n",
    "\n",
    "Sa matrice associée est :\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "**Interprétation :**  \n",
    "$\n",
    "f(x, y, z) = A \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}\n",
    "$ \n",
    "\n",
    "\n",
    "### **Exercices d'application (1.2.1)**  \n",
    "On donne : $ f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3 $ définie par :\n",
    "$ f(x, y, z) = (y + 3z, 4x - 7z, x ) $ puis la matrice :\n",
    "$\n",
    "Z = \\begin{pmatrix}\n",
    "1 & 0 & -5 \\\\\n",
    "0 & 5 & 2 \\\\\n",
    "\\end{pmatrix}\n",
    "$ \n",
    "\n",
    "1. Donne la matrice $M$ associée à $f$. \n",
    "2. Donne l'application linéaire $h$ associée à $Z$ puis calcule l'image de $(0; 1; 0)$ par $h$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bf571f9-e8cb-4283-9137-9f3a84173af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format de la Matrice A : (3, 4)\n",
      "Nombre de coefficient dans A : 12\n"
     ]
    }
   ],
   "source": [
    "# Représentation d'une matrice avec numpy\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [2, -1, 1, 0],\n",
    "    [1, 3, -2, 1],\n",
    "    [-1, 4, 5, 0]\n",
    "])\n",
    "print(f'format de la Matrice A : {A.shape}')\n",
    "print(f'Nombre de coefficient dans A : {A.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7c450-018a-42e2-82bb-38329eb2d60e",
   "metadata": {},
   "source": [
    "----\n",
    "### **1.2.2. Opérations sur les Matrices** \n",
    "----\n",
    "#### **A. Addition de Matrices**  \n",
    "Si $A$ et $B$ sont deux matrices de même taille, alors $ C = A + B $ est définie par :\n",
    "$\n",
    "c_{ij} = a_{ij} + b_{ij}\n",
    "$  \n",
    "\n",
    "**Exemple :**  \n",
    "\n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}, \\qquad\n",
    "B = \\begin{pmatrix}\n",
    "9 & 8 & 7 \\\\\n",
    "6 & 5 & 4 \\\\\n",
    "3 & 2 & 1\n",
    "\\end{pmatrix}\n",
    "$    \n",
    "\n",
    "$\n",
    "A + B = \\begin{pmatrix}\n",
    "1+9 & 2+8 & 3+7 \\\\\n",
    "4+6 & 5+5 & 6+4 \\\\\n",
    "7+3 & 8+2 & 9+1\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "10 & 10 & 10 \\\\\n",
    "10 & 10 & 10 \\\\\n",
    "10 & 10 & 10\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "#### **B. Multiplication par un Scalaire**  \n",
    "Si $ \\lambda \\in \\mathbb{R} $, alors $ \\lambda A $ est définie par :\n",
    "$ (\\lambda A)_{ij} = \\lambda \\cdot a_{ij} $  \n",
    "\n",
    "**Exemple :**  \n",
    "\n",
    "$\n",
    "2A = 2 \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "2 & 4 & 6 \\\\\n",
    "8 & 10 & 12 \\\\\n",
    "14 & 16 & 18\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "#### **C. Produit Matriciel**  \n",
    "Si $ A $ est de taille $ m \\times n $ et $ B $ de taille $n \\times p $, alors $ C = A \\times B $ est de taille $ m \\times p $ avec : $\\qquad$\n",
    "$ c_{ij} = \\sum_{k=1}^n a_{ik} \\cdot b_{kj} $  \n",
    "\n",
    "- **Le produit matriciel $A \\times B$ est possible uniquement si le nombre de colonnes dans $𝐴$ est égal au nombre de lignes dans $𝐵$**\n",
    "- **Le produit matriciel n'est pas commutatif ($A \\times B$ n'est pas forcement égal à $B \\times A$).**\n",
    "\n",
    "**Exemple :**  \n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}, \\quad\n",
    "B = \\begin{pmatrix}\n",
    "9 & 8 \\\\\n",
    "6 & 5 \\\\\n",
    "3 & 2\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "A \\times B = \\begin{pmatrix}\n",
    "(1 \\cdot 9 + 2 \\cdot 6 + 3 \\cdot 3) & (1 \\cdot 8 + 2 \\cdot 5 + 3 \\cdot 2) \\\\\n",
    "(4 \\cdot 9 + 5 \\cdot 6 + 6 \\cdot 3) & (4 \\cdot 8 + 5 \\cdot 5 + 6 \\cdot 2) \\\\\n",
    "(7 \\cdot 9 + 8 \\cdot 6 + 9 \\cdot 3) & (7 \\cdot 8 + 8 \\cdot 5 + 9 \\cdot 2)\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "30 & 24 \\\\\n",
    "84 & 69 \\\\\n",
    "138 & 114\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "#### **D. Transposée d’une Matrice**  \n",
    "La transposée $ A^T $ est obtenue en échangeant les lignes et les colonnes.  \n",
    "\n",
    "**Exemple :**  \n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{pmatrix}, \\quad\n",
    "A^T = \\begin{pmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "3 & 6\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "\n",
    "\n",
    "### **Exercices d’Application**  \n",
    "\n",
    "#### **Exercice 1 (Addition & Multiplication par un Scalaire)**  \n",
    "Soient : \n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "2 & 0 & -1 \\\\\n",
    "3 & 1 & 4 \\\\\n",
    "-2 & 5 & 7\n",
    "\\end{pmatrix}, \\quad\n",
    "B = \\begin{pmatrix}\n",
    "1 & 3 & 2 \\\\\n",
    "-4 & 0 & 5 \\\\\n",
    "6 & -2 & 1\n",
    "\\end{pmatrix} et \\quad\n",
    "C = \\begin{pmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "3 & 0 & 2\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "Calculer si possible:  \n",
    "1. $ A + B $\n",
    "2. $ B + C $\n",
    "3. $ 3A - 2B $  \n",
    "\n",
    "#### **Exercice 2 (Produit Matriciel)**  \n",
    "Soient :  \n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "-1 & 3 \\\\\n",
    "2 & 4\n",
    "\\end{pmatrix}, \\quad\n",
    "B = \\begin{pmatrix}\n",
    "0 & -1 \\\\\n",
    "4 & 2\n",
    "\\end{pmatrix}, \\quad\n",
    "C = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "2 & 9 & 6 \\\\\n",
    "\\end{pmatrix}\n",
    "$ $\\quad$\n",
    "$\n",
    "D = \\begin{pmatrix}\n",
    "4 \\\\\n",
    "0 \\\\\n",
    "7 \\\\\n",
    "\\end{pmatrix}\n",
    "$ $\\quad$\n",
    "$\n",
    "E = \\begin{pmatrix}\n",
    "3 & 2 & 3 \\\\\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "1. Calculer $ A \\times B $ et $ B \\times A $ puis conclut.\n",
    "2. Calculer si possible :  \n",
    "   2.1. $ C \\times E $  \n",
    "   2.2. $ D \\times E $  \n",
    "   2.3. $ E \\times D $  \n",
    "\n",
    "#### **Exercice 3 (Application Linéaire)**  \n",
    "Soit $ f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3 $ définie par :  \n",
    "$\n",
    "f(x, y, z) = (2x - y + z, x + 3y - 2z, -x + 4y + 5z)\n",
    "$  \n",
    "1. Donner la matrice associée $ A $.  \n",
    "2. Calculer $ f(1, -1, 2) $ en utilisant $ A $.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69ac282b-82bf-4e79-8635-208966a5cad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A + B = \n",
      " [[ 3  3  1]\n",
      " [-1  1  9]\n",
      " [ 4  3  8]]\n",
      "\n",
      " 3A - 2B =\n",
      " [[  4  -6  -7]\n",
      " [ 17   3   2]\n",
      " [-18  19  19]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Définition des matrices\n",
    "A = np.array([[2, 0, -1], [3, 1, 4], [-2, 5, 7]])\n",
    "B = np.array([[1, 3, 2], [-4, 0, 5], [6, -2, 1]])\n",
    "C = np.array([[1, 1, 1], [3, 0, 2]])  # Note: C a une forme (2,3), incompatible avec A et B (3,3)\n",
    "# 1. A + B\n",
    "print(\" A + B = \\n\", A + B)\n",
    "# 2. B + C\n",
    "#print(\"\\n B + C =\\n\", B + C)\n",
    "# 3. 3A - 2B\n",
    "print(\"\\n 3A - 2B =\\n\", 3*A - 2*B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfca4fc0-2804-4f0d-850e-1db16fd0dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A × B =\n",
      " [[12  7]\n",
      " [16  6]]\n",
      "\n",
      " B × A =\n",
      " [[-2 -4]\n",
      " [ 0 20]]\n",
      "Conclusion : ---- ---- ----\n",
      "\n",
      " D × E =\n",
      " [[12  8 12]\n",
      " [ 0  0  0]\n",
      " [21 14 21]]\n",
      "\n",
      " E × D =\n",
      " [[33]]\n"
     ]
    }
   ],
   "source": [
    "# Définition des matrices\n",
    "A = np.array([[-1, 3], [2, 4]])\n",
    "B = np.array([[0, -1], [4, 2]])\n",
    "C = np.array([[1, 2, 3], [2, 9, 6]])\n",
    "D = np.array([[4], [0], [7]])  # (3x1)\n",
    "E = np.array([[3, 2, 3]])      # (1x3)\n",
    "\n",
    "# 1. A × B et B × A\n",
    "print(\" A × B =\\n\", np.dot(A, B))\n",
    "print(\"\\n B × A =\\n\", np.dot(B, A))\n",
    "print(\"Conclusion : ---- ---- ----\")\n",
    "# 2.1 C × E\n",
    "#print(\"\\n C × E =\\n\", C @ E)\n",
    "# 2.2 D × E \n",
    "print(\"\\n D × E =\\n\", D @ E)\n",
    "# 2.3 E × D \n",
    "print(\"\\n E × D =\\n\", E @ D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce0dc492-c572-4dfb-b86b-70f428cd1658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Matrice A =\n",
      " [[ 2 -1  1]\n",
      " [ 1  3 -2]\n",
      " [-1  4  5]]\n",
      "\n",
      "2. f(1, -1, 2) = [ 5 -6  5]\n"
     ]
    }
   ],
   "source": [
    "# 1. Matrice associée A\n",
    "A = np.array([[2, -1, 1], [1, 3, -2], [-1, 4, 5]])\n",
    "print(\"1. Matrice A =\\n\", A)\n",
    "# 2. Calcul de f(1, -1, 2)\n",
    "vecteur = np.array([1, -1, 2])\n",
    "print(\"\\n2. f(1, -1, 2) =\", np.dot(A, vecteur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7488d-24d0-4a5d-9e9a-a8f2eb3d7d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82a90537-e542-4478-826a-283751651dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3]) \n",
    "b = np.array([4,5,6])\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37c6b4-a8b2-48be-9929-f67c75d8c59c",
   "metadata": {},
   "source": [
    "----\n",
    "### **1.2.3. Calcul de l’Inverse d’une Matrice**   \n",
    "----  \n",
    "#### **A. Introduction : Pourquoi Calculer l’Inverse d’une Matrice ?**  \n",
    "\n",
    "L’inverse d’une matrice est un concept fondamental en algèbre linéaire, particulièrement utile en **intelligence artificielle** pour :  \n",
    "- **Résoudre des systèmes d’équations linéaires** (alternative à la méthode du pivot de Gauss).  \n",
    "- **Trouver des solutions optimales** dans les problèmes d’optimisation (régression linéaire, moindres carrés).  \n",
    "- **Effectuer des transformations géométriques inverses** (en vision par ordinateur, robotique).\n",
    "\n",
    "**Définition :**  \n",
    "Une matrice carrée $A$ d’ordre $n$ est **inversible** s’il existe une matrice $B$ telle que :  \n",
    "$\n",
    "A \\times B = B \\times A = I_n\n",
    "$  \n",
    "où $ I_n $ est la matrice identité. On note $ B = A^{-1} $.  \n",
    "\n",
    "#### **B. Conditions d’Inversibilité**  \n",
    "Une matrice $ A $ est inversible **si et seulement si** :  \n",
    "- Son **déterminant est non nul** ($ \\det(A) \\neq 0 $).  \n",
    "- Ses colonnes (ou lignes) sont **linéairement indépendantes**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec906ae-80a6-4cfb-98c5-ca5e796e868c",
   "metadata": {},
   "source": [
    "#### **C. Méthodes pour Calculer l’Inverse d’une Matrice**  \r\n",
    "\r\n",
    "##### **i) Méthode du Déterminant et des Comatrice**  \r\n",
    "Formule de l’inverse d’une matrice $ A $ :  \r\n",
    "$$ A^{-1} = \\frac{1}{\\det(A)} \\cdot \\text{Com}(A)^T $$  où :\r\n",
    "- $ \\det(A) $ est le **déterminant** de la matrice,\r\n",
    "- $ \\text{Com}(A) $ est la **comatrice** de $ A $ (la matrice des cofacteurs),\r\n",
    "- $ \\text{Com}(A)^T $ est la **transposée** de la comatrice.\r\n",
    "\r\n",
    "##### **ii) Méthode par Pivot de Gauss (Élimination Linéaire)**  \r\n",
    "On transforme $ [A | I_n] $ en $ [I_n | A^{-1}] $ via des opérations élémentaires.  \r\n",
    "\r\n",
    "**Exemple :**  \r\n",
    "$$\r\n",
    "\\begin{pmatrix}\r\n",
    "1 & 2 & 3 & | & 1 & 0 & 0 \\\\\r\n",
    "0 & 1 & 4 & | & 0 & 1 & 0 \\\\\r\n",
    "5 & 6 & 0 & | & 0 & 0 & 1\r\n",
    "\\end{pmatrix} \\xrightarrow{\\text{opérations}} \\begin{pmatrix}\r\n",
    "1 & 0 & 0 & | & -24 & 18 & 5 \\\\\r\n",
    "0 & 1 & 0 & | & 20 & -15 & -4 \\\\\r\n",
    "0 & 0 & 1 & | & -5 & 4 & 1\r\n",
    "\\end{pmatrix}\r\n",
    "$$ \r\n",
    "\r\n",
    "#### **D. Applications de l’Inverse Matriciel**  \r\n",
    "\r\n",
    "##### **i) Résolution de Systèmes Linéaires**  \r\n",
    "Si $ AX = B $, alors $ X = A^$\r\n",
    "\\begin{cases}\r\n",
    "x + 2y + 3z = 6 \\\\\r\n",
    "y + 4z = 9 \\\\\r\n",
    "5x + 6y = 3\r\n",
    "\\end{cases} \\Rightarrow X = A^{-1} \\begin{pmatrix} 6 \\\\ 9 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} -24 \\cdot 6 + 18 \\cdot 9 + 5 \\cdot 3 \\\\ 20 \\cdot 6 -15 \\cdot 9 -4\\cdot 3 \\\\ -5 \\cdot 6 +4 \\cdot 9 +1\\cdot 3 \\end{pmatrix} = \\begin{pmatrix} 33 \\\\ -27 \\\\ 9 \\end{pmatrix}\r\n",
    "$  trix} 1 \\\\ -3 \\\\ 3 \\end{pmatrix}\r\n",
    "$   \r\n",
    "\r\n",
    "\r\n",
    "##### **ii) Régression Linéaire (Moindres Carrés)**  \r\n",
    "La solution de $ \\theta = (X^T X)^{-1} X^T Y $ nécessite l’inversion de $ X^T X $.  \r\n",
    "Mais attention, on préfère des méthodes numériques approximatives comme la **descente de gradient** car l'inversion de grande matrice coûte très cher.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef395c7-8ea5-4e48-b1ad-2277d6088673",
   "metadata": {},
   "source": [
    "er.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0cc1b22c-a7b5-4dac-bda5-393300027fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution X = [ 33. -27.   9.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Définition de la matrice A et du vecteur B\n",
    "A = np.array([[1, 2, 3],\n",
    "              [0, 1, 4],\n",
    "              [5, 6, 0]])\n",
    "B = np.array([6, 9, 3])\n",
    "\n",
    "# Vérification que A est inversible\n",
    "if np.linalg.det(A) != 0:\n",
    "    # Calcul de l'inverse de A\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    # Solution X = A^{-1} * B\n",
    "    X = np.dot(A_inv, B)\n",
    "    print(\"Solution X =\", X)\n",
    "else:\n",
    "    print(\"La matrice A n'est pas inversible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f475203-9fbf-4708-988a-115bea593a32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercices d’Application**  \n",
    "\n",
    "### **Exercice 1 (Inverse par Cofacteurs)**  \n",
    "Calculer $ A^{-1} $ pour :  \n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "2 & 0 & -1 \\\\\n",
    "3 & 1 & 4 \\\\\n",
    "-2 & 5 & 7\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "### **Exercice 2 (Résolution de Système)**  \n",
    "Résoudre en utilisant $ A^{-1} $ :  \n",
    "$\n",
    "\\begin{cases}\n",
    "2x - z = 1 \\\\\n",
    "3x + y + 4z = 0 \\\\\n",
    "-2x + 5y + 7z = 3\n",
    "\\end{cases}\n",
    "$  \n",
    "\n",
    "### **Exercice 3 (Inverse par Gauss)**  \n",
    "Trouver $ B^{-1} $ par pivot de Gauss :  \n",
    "$\n",
    "B = \\begin{pmatrix}\n",
    "1 & 0 & 2 \\\\\n",
    "-1 & 3 & 1 \\\\\n",
    "2 & 4 & 0\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "---\n",
    "\n",
    "## **Corrigés (Extraits)**  \n",
    "\n",
    "### **Corrigé Exercice 1**  \n",
    "$\n",
    "\\det(A) = 2(1 \\cdot 7 - 4 \\cdot 5) - 0 + (-1)(3 \\cdot 5 - 1 \\cdot (-2)) = -46  \n",
    "$  \n",
    "$\n",
    "A^{-1} = -\\frac{1}{46} \\begin{pmatrix}\n",
    "-13 & 5 & 1 \\\\\n",
    "29 & 12 & -11 \\\\\n",
    "17 & -10 & 2\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "### **Corrigé Exercice 2**  \n",
    "$\n",
    "X = A^{-1} \\begin{pmatrix} 1 \\\\ 0 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\end{pmatrix}\n",
    "$  \n",
    "\n",
    "### **Corrigé Exercice 3**  \n",
    "$\n",
    "B^{-1} = \\begin{pmatrix}\n",
    "-4 & 8 & -6 \\\\\n",
    "2 & -4 & 3 \\\\\n",
    "10 & -4 & 3\n",
    "\\end{pmatrix}\n",
    "$  \n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion :** L’inversion matricielle est cruciale en IA pour la résolution de problèmes linéaires et l’optimisation. Les méthodes présentées (déterminant, cofacteurs, Gauss) sont des outils de base en algèbre linéaire appliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925eff6-a292-4604-8a4e-c17b2e8a17e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719713b-ba0b-4e4b-9177-368e9d07d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633c3095-23a1-4a64-8e52-c71108d39731",
   "metadata": {},
   "source": [
    "# Travail à rendre avant Jeudi 1er mai à 23h 59.  \n",
    "\n",
    "\n",
    "1. Implémente une fonction **produit_scalaire(vecteur1, vecteur2)** qui prend en entrée deux listes et qui retourne le produit scalaire des deux vecteurs s'ils ont même taille sinon il retourne **None**\n",
    "2. Implémente une fonction **norme_1(vecteur)** ( resp. **norme_2(vecteur)** ) qui prend en entrée une liste ou un tuple de nombres réels puis retourne la **norme 1** (resp. la **norme 2**) du vecteur en utilisant **numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba27caa-d432-4459-a40c-db0fe38cb19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
